{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "535b7226-eb4c-49e1-b3d7-8c5309a72b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_baseline.py\n"
     ]
    }
   ],
   "source": [
    "!ls CPSC477/subtaskA/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "872a240a-35ac-4d59-bc90-b46f91acf6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 21:45:34.933995: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-08 21:45:34.985280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 21:45:36.607980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.relpath(\"CPSC477/subtaskA/baseline\"))\n",
    "from transformer_baseline import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29d21fde-1f4c-46af-8e10-081139dce7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import set_seed\n",
    "import logging\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe5f572-96f1-428a-9e32-355a447500aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b93544591e4f28965789a1ab89909c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cpsc477_jhy24/.conda/envs/cs477/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated base on synonym2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425f04ddd1324571b7fa63e29e1ba9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cpsc477_jhy24/.conda/envs/cs477/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated synonym on synonym2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6940e1bf7dff4ee4a39410e8e58ced6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cpsc477_jhy24/.conda/envs/cs477/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated homoglyph on synonym2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814aaae86cdb4240a7eb51a0d0fb9caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cpsc477_jhy24/.conda/envs/cs477/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated base on duplicate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a057abc467485d93fe86cf6960c411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cpsc477_jhy24/.conda/envs/cs477/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated synonym on duplicate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e01a941439481cb5200d9ea5788a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34272 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/cpsc477_jhy24/.conda/envs/cs477/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated homoglyph on duplicate\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation script (all models -> all datasets)\n",
    "\n",
    "id2label = {0: \"human\", 1: \"machine\"}\n",
    "label2id = {\"human\": 0, \"machine\": 1}\n",
    "\n",
    "for dataset in [\"subtaskA\", \"synonym\", \"synonym2\", \"homoglyph\", \"duplicate\"]:\n",
    "    set_seed(0)\n",
    "    \n",
    "    #using test sets for final evaluation now; previously set to dev sets\n",
    "    test_df = pd.read_json(f\"CPSC477/subtaskA/data/{dataset}_test.jsonl\", lines=True)\n",
    "    \n",
    "    for model in [\"base\", \"synonym\", \"synonym2\", \"homoglyph\", \"duplicate\"]:\n",
    "        results, predictions = test(test_df, f\"{model}-roberta/subtaskA/0/best/\", id2label, label2id)\n",
    "            \n",
    "        logging.info(results)\n",
    "        predictions_df = pd.DataFrame({'id': test_df['id'], 'label': predictions})\n",
    "        predictions_df.to_json(f\"CPSC477/subtaskA/pred/{model}_on_{dataset}.jsonl\", lines=True, orient='records')\n",
    "        print(\"Evaluated \" + model + \" on \" + dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8100b89e-351e-4d0c-8fb0-c71a9943394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtaskA\n",
      "0.8418825863678805\n",
      "synonym\n",
      "0.8911356209150327\n",
      "synonym2\n",
      "0.884016106442577\n",
      "homoglyph\n",
      "0.559640522875817\n",
      "duplicate\n",
      "0.8602941176470589\n"
     ]
    }
   ],
   "source": [
    "# Ensemble code\n",
    "\n",
    "for dataset in [\"subtaskA\", \"synonym\", \"synonym2\", \"homoglyph\", \"duplicate\"]:\n",
    "    first_file = pd.read_json(f\"CPSC477/subtaskA/pred/base_on_{dataset}.jsonl\", lines=True)[['id', 'label']]\n",
    "    second_file = pd.read_json(f\"CPSC477/subtaskA/pred/synonym_on_{dataset}.jsonl\", lines=True)[['id', 'label']]\n",
    "    third_file = pd.read_json(f\"CPSC477/subtaskA/pred/synonym2_on_{dataset}.jsonl\", lines=True)[['id', 'label']]\n",
    "    fourth_file = pd.read_json(f\"CPSC477/subtaskA/pred/homoglyph_on_{dataset}.jsonl\", lines=True)[['id', 'label']]\n",
    "    fifth_file = pd.read_json(f\"CPSC477/subtaskA/pred/duplicate_on_{dataset}.jsonl\", lines=True)[['id', 'label']]\n",
    "    \n",
    "    pred_labels = pd.concat([first_file, second_file, third_file, fourth_file, fifth_file], axis=0)\n",
    "    pred_labels = pred_labels.groupby(['id']).mean()\n",
    "    pred_labels = pred_labels.round(0).astype(int)\n",
    "\n",
    "    gold_labels = pd.read_json(\"CPSC477/subtaskA/data/subtaskA_test.jsonl\", lines=True)[['id', 'label']]\n",
    "    \n",
    "    merged_df = pred_labels.merge(gold_labels, on='id', suffixes=('_pred', '_gold'))\n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(merged_df['label_gold'], merged_df['label_pred'])\n",
    "\n",
    "    print(dataset)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb03b80-8611-4a9e-bee9-e4a2bd430b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
